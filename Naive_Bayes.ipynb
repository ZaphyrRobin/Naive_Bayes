{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import Spark and MLlib packages\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "from pyspark.mllib.classification import NaiveBayes\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "#import data analysis packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from numpy import array\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "#import data visualization packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "#misc packages\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I.Load dataset\n",
    "#The dataset is picked from here https://github.com/mwaskom/seaborn-data\n",
    "iris = sns.load_dataset(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_size is 150, feature_size is 5\n"
     ]
    }
   ],
   "source": [
    "#Get the data size and feature size\n",
    "data_size, feature_size = iris.shape\n",
    "print(\"data_size is {}, feature_size is {}\".format(data_size, feature_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#II. datacleaning for PySpark\n",
    "#1.Label Setosa as 0, Versicolor as 1, Virginica as 2\n",
    "species = iris.species\n",
    "label_species = []\n",
    "for i in range(len(species)):\n",
    "    if species[i] == 'setosa':\n",
    "        label_species.insert(i, 0)\n",
    "    elif species[i] == 'versicolor':\n",
    "        label_species.insert(i, 1)\n",
    "    else :\n",
    "        label_species.insert(i, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2.Convert list to Series so that it can be load to dataframe\n",
    "series_species = Series(label_species, index = range(len(species)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width  species\n",
      "0           5.1          3.5           1.4          0.2        0\n",
      "1           4.9          3.0           1.4          0.2        0\n",
      "2           4.7          3.2           1.3          0.2        0\n",
      "3           4.6          3.1           1.5          0.2        0\n",
      "4           5.0          3.6           1.4          0.2        0\n"
     ]
    }
   ],
   "source": [
    "#3.Reload Series to Species column \n",
    "iris['species'] = series_species\n",
    "print(iris.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4.Move Species column to the first column\n",
    "cols = iris.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "iris = iris[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 0</td>\n",
       "      <td> 5.1</td>\n",
       "      <td> 3.5</td>\n",
       "      <td> 1.4</td>\n",
       "      <td> 0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 0</td>\n",
       "      <td> 4.9</td>\n",
       "      <td> 3.0</td>\n",
       "      <td> 1.4</td>\n",
       "      <td> 0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 0</td>\n",
       "      <td> 4.7</td>\n",
       "      <td> 3.2</td>\n",
       "      <td> 1.3</td>\n",
       "      <td> 0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 0</td>\n",
       "      <td> 4.6</td>\n",
       "      <td> 3.1</td>\n",
       "      <td> 1.5</td>\n",
       "      <td> 0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 0</td>\n",
       "      <td> 5.0</td>\n",
       "      <td> 3.6</td>\n",
       "      <td> 1.4</td>\n",
       "      <td> 0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species  sepal_length  sepal_width  petal_length  petal_width\n",
       "0        0           5.1          3.5           1.4          0.2\n",
       "1        0           4.9          3.0           1.4          0.2\n",
       "2        0           4.7          3.2           1.3          0.2\n",
       "3        0           4.6          3.1           1.5          0.2\n",
       "4        0           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#III. Using Sciki-learn SVC \n",
    "#This time, let's analysis the last two features \n",
    "#petal_length and petal_width\n",
    "data_col = cols[-2:]\n",
    "\n",
    "#Target data\n",
    "Y = iris['species']\n",
    "\n",
    "#Traning and testing dataset\n",
    "X = iris[data_col] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   petal_length  petal_width\n",
      "0           1.4          0.2\n",
      "1           1.4          0.2\n",
      "2           1.3          0.2\n",
      "3           1.5          0.2\n",
      "4           1.4          0.2\n"
     ]
    }
   ],
   "source": [
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145    2\n",
      "146    2\n",
      "147    2\n",
      "148    2\n",
      "149    2\n",
      "Name: species, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 2) (38, 2) (112,) (38,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into Trainging and Testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['petal_length'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model and Predict\n",
    "NB_multi = MultinomialNB().fit(X_train, Y_train)\n",
    "NB_Bernou = BernoulliNB().fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomail Naive Bayes accuracy is 0.5\n",
      "Bernoulli Naive Bayes accuracy is 0.263157894737\n"
     ]
    }
   ],
   "source": [
    "for i , clf in enumerate((NB_multi, NB_Bernou)):\n",
    "    predicted = clf.predict(X_test)\n",
    "    expected = Y_test\n",
    "    \n",
    "    #compare results\n",
    "    errors = metrics.accuracy_score(expected, predicted)\n",
    "    if i == 0:\n",
    "        print(\"Multinomail Naive Bayes accuracy is {}\".format(errors))\n",
    "    else:\n",
    "        print(\"Bernoulli Naive Bayes accuracy is {}\".format(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dump the tips to a local file for now\n",
    "X_data_size = len(X['petal_length'])\n",
    "Y = np.vstack(Y)\n",
    "\n",
    "fo = open(\"/usr/local/spark/examples/src/main/resources/iris_3.data\", \"w\")\n",
    "for i in range(X_data_size):    \n",
    "    fo.write(\"{},{} {}\\n\".format(float(Y[i][0]), float(X['petal_length'][i]), float(X['petal_width'][i]))) \n",
    "\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#IV Use MLlib\n",
    "sc = SparkContext(\"local\", \"SVM_LogisticRegression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#code parsing function and load data\n",
    "def parseLine(line):\n",
    "    parts = line.split(',')\n",
    "    label = float(parts[0])\n",
    "    features = Vectors.dense([float(x) for x in parts[1].split(' ')])\n",
    "    return LabeledPoint(label, features)\n",
    "\n",
    "data = sc.textFile('/usr/local/spark/examples/src/main/resources/iris_3.data').map(parseLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [1.4,0.2]),\n",
       " LabeledPoint(0.0, [1.4,0.2]),\n",
       " LabeledPoint(0.0, [1.3,0.2]),\n",
       " LabeledPoint(0.0, [1.5,0.2]),\n",
       " LabeledPoint(0.0, [1.4,0.2]),\n",
       " LabeledPoint(0.0, [1.7,0.4]),\n",
       " LabeledPoint(0.0, [1.4,0.3]),\n",
       " LabeledPoint(0.0, [1.5,0.2]),\n",
       " LabeledPoint(0.0, [1.4,0.2]),\n",
       " LabeledPoint(0.0, [1.5,0.1])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Split the training set and test set\n",
    "#from what we used in scikit-learn part, 112/150 = 75%\n",
    "training, test = data.randomSplit([0.75, 0.25], seed = 0)\n",
    "\n",
    "#Training model\n",
    "model = NaiveBayes.train(training, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PySpark NaiveBayes model accuracy 0.222222222222\n"
     ]
    }
   ],
   "source": [
    "#predict and test accuracy\n",
    "predictionAndLabel = test.map(lambda p: (model.predict(p.features), p.label))\n",
    "accuracy = predictionAndLabel.filter(lambda (x, v): x == v).count()/test.count()\n",
    "\n",
    "print(\"PySpark NaiveBayes model accuracy {}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
